---
layout: default
pagination:
enabled: true
---
<!-- Place this tag in your head or just before your close body tag. -->
<script async defer src="https://buttons.github.io/buttons.js"></script>

<div class="home">

  <div class="site-header-container {% if site.cover %}has-cover{% endif %}"
    {% if site.cover %}style="background-image: url({{ site.cover | prepend: site.baseurl }});" {% endif %}>
    <div class="scrim {% if site.cover %}has-cover{% endif %}">
      <header class="site-header">
        <h1 class="title" style=font-size:80px>{{ site.title }}</h1>
        {% if site.subtitle %}<p class="title" style=font-size:30px>{{ site.subtitle }}</p>{% endif %}
      </header>
    </div>
  </div>

  <div class="wrapper">
    <h1 id="headings">Introduction</h1>
    <p style="text-align: justify">
      Policy Search and Model Predictive Control (MPC) are two different paradigms for robot control:
      policy search has the strength of automatically learning complex policies using experienced data,
      while MPC can offer optimal control performance using models and trajectory optimization. 
      An open research question is how to leverage and combine the advantages of both approaches.
      In this work, we provide an answer by using policy search for automatically choosing high-level decision variables for MPC, 
      which leads to a novel <b>policy-search-for-model-predictive-control framework</b>. 
      Specifically, we formulate the MPC as a parameterized controller, where the hard-to-optimize
      decision variables are represented as high-level policies.
      Such a formulation allows optimizing policies in a self-supervised fashion. 
      We validate this framework by focusing on a challenging problem in agile drone flight: 
      flying a quadrotor through fast-moving gates.
      Experiments show that our controller achieves robust and real-time control performance in both simulation and the real world. 
      The proposed framework offers a new perspective for merging learning and control.  
    </p>

    <h2 id="headings">Code</h2>
       You can find the code in <a href="https://github.com/uzh-rpg/high_mpc">GitHub</a>
    
    </p>


    <div class="container" style="margin-top:30px;margin-bottom:30px;">
      <h2>Publication</h2>
      If you use this code in a publication, please cite our paper.

    </p>
      Y. Song and D. Scaramuzza, <b>"Policy Search for Model Predictive Control with Application to Agile Drone Flight," </b>
      IEEE Transaction on Robotics (T-RO), 2021. 
      <a href="http://rpg.ifi.uzh.ch/docs/TRO21_Yunlong.pdf">[PDF]</a> 
      <a href="https://youtu.be/Qei7oGiEIxY">[YouTube]</a> 

    </p>

       Y. Song and D. Scaramuzza, <b>"Learning High-Level Policies for Model Predictive Control," </b> 
      IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Las Vegas, 2020. 
       <a href="http://rpg.ifi.uzh.ch/docs/IROS20_Yunlong.pdf">[PDF]</a> 
      <a href="https://youtu.be/2uQcRnp7yI0">[YouTube]</a> 

<pre>
<code class="pre-scrollable" style="background:#ffffff;color:#333;font-size:12px;padding:0px;border-width:0px;">
@article{song2022policy,
author={Song, Yunlong and Scaramuzza, Davide},
journal={IEEE Transactions on Robotics},
title={Policy Search for Model Predictive Control With Application to Agile Drone Flight},
year={2022},
pages={1-17},
doi={10.1109/TRO.2022.3141602}
}
</code>
</pre>

<pre>
<code class="pre-scrollable" style="background:#ffffff;color:#333;font-size:12px;padding:0px;border-width:0px;">
@inProceedings{song2020learning,
title={Learning High-Level Policies for Model Predictive Control},
author={Song, Yunlong and Scaramuzza, Davide},
booktitle={IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
year={2020}
}
</code>
</pre>
    </p>
    <h2 id="headings">Demonstrations</h2> 
    Please find a list of demonstrations in
    <a href="https://github.com/uzh-rpg/high_mpc/blob/master/docs/gifs/README.md">here</a> and in the video below:

    </p>

    <iframe width="700" height="406" src="https://www.youtube.com/embed/Qei7oGiEIxY" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

    </p>

    <h2 id="headings">Contributions</h2>
    <ul>
      <li>A Novel Framework for Merging Reinforcement Learning and Model Predictive Control</li>
      <li>An Autonomous System That Controls A Quadrotor to Fly Through Dynamic Gates</li>
    </ul>

    </p>

    <h2 id="headings">People</h2> 
<div id="people">
  <div class="inline-block">
    <a href="http://yun-long.github.io/">
    <img class="circular--square" src="{{site.baseurl}}/assets/people/yunlong.jpg" style="width: 200px">
    <p style="text-align:center"><strong>Yunlong Song</strong></p>
    </a>
  </div>
  <div class="inline-block">
    <a href="http://rpg.ifi.uzh.ch/people_scaramuzza.html">
    <img class="circular--square" src="{{site.baseurl}}/assets/people/davide.png" style="width: 200px">
    <p style="text-align:center"><strong>Prof. Davide Scaramuzza</strong></p>
    </a>
  </div>
</div>

  </div>



</div>